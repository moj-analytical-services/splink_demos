{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d729e302",
   "metadata": {},
   "source": [
    "# Specifying and estimating a linkage model\n",
    "\n",
    "\n",
    "In the last tutorial we looked at how we can use blocking rules to generate pairwise record comparisons.\n",
    "\n",
    "Now it's time to build a probabilistic linkage model to score each of these comparisons.\n",
    "\n",
    "The resultant match score is a prediction of whether the two records represent the same entity (e.g. are the same person).  You can read more about the theory behind probabilistic linkage models [here](https://www.robinlinacre.com/intro_to_probabilistic_linkage/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by reading in the tutorial data again\n",
    "from splink.duckdb.duckdb_linker import DuckDBLinker\n",
    "import pandas as pd \n",
    "import altair as alt\n",
    "alt.renderers.enable(\"mimetype\")\n",
    "df = pd.read_csv(\"./data/fake_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f104340",
   "metadata": {},
   "source": [
    "##  Specifying a linkage model\n",
    "\n",
    "To produce a match score, `splink` needs to know how to compare the information in our pairwise record comparions.\n",
    "\n",
    "To be concrete, here is an example comparison:\n",
    "\n",
    "\n",
    "first_name_l|first_name_r|surname_l|surname_r|dob_l     |dob_r     |city_l|city_r|email_l            |email_r            |\n",
    "------------|------------|---------|---------|----------|----------|------|------|-------------------|-------------------|\n",
    "Robert      |Rob         |Allen    |Allen    |1971-05-24|1971-06-24|nan   |London|roberta25@smith.net|roberta25@smith.net|\n",
    "\n",
    "What functions should we use to assess the similarity of `Rob` vs. `Robert` in the the `first_name` field?  \n",
    "\n",
    "Should similarity in the `dob` field be computed in the same way, or a different way?\n",
    "\n",
    "Your job as the developer of a linkage model is to decide what comparisons are most appropriate for the types of data you have.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a520392",
   "metadata": {},
   "source": [
    "### Comparisons\n",
    "\n",
    "The concept of a `Comparison` has a specific definition within Splink: it defines how data from one or more input columns is compared, using SQL expressions assess similarity.\n",
    "\n",
    "For example, one `Comparison` may represent how similarity is assessed for a person's date of birth.  \n",
    "\n",
    "\n",
    "\n",
    "Another `Comparison` may represent the comparison of a person's name or location.\n",
    "\n",
    "\n",
    "\n",
    "A model will thereby be composed of many `Comparison`s, which between them assess the similarity of all of the columns being used for data linking.  \n",
    "\n",
    "Each `Comparison` contains two or more `ComparisonLevels` which define _n_ discrete gradations of similarity between the input columns within the Comparison.\n",
    "\n",
    "As such `ComparisonLevels`are nested within `Comparisons` as follows:\n",
    "\n",
    "```\n",
    "Data Linking Model\n",
    "├─-- Comparison: Date of birth\n",
    "│    ├─-- ComparisonLevel: Exact match\n",
    "│    ├─-- ComparisonLevel: One character difference\n",
    "│    ├─-- ComparisonLevel: All other\n",
    "├─-- Comparison: Surname\n",
    "│    ├─-- ComparisonLevel: Exact match on surname\n",
    "│    ├─-- ComparisonLevel: All other\n",
    "│    etc.\n",
    "```\n",
    "\n",
    "Our example data would therefore result in the following comparisons, for `dob` and `surname`:\n",
    "\n",
    "|dob_l     |dob_r     |comparison_level|\n",
    "|----------|----------|---------|\n",
    "|1971-05-24|1971-06-24|One character difference|\n",
    "\n",
    "\n",
    "\n",
    "surname_l|surname_r|comparison_level|\n",
    "---------|---------|---------|\n",
    "Allen    |Allen    |Exact match|\n",
    "\n",
    "More information about comparisons can be found [here](https://moj-analytical-services.github.io/splink/comparison.html).\n",
    "\n",
    "\n",
    "We will now use these concepts to build a data linking model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02000a24",
   "metadata": {},
   "source": [
    "### Specifying the model using comparisons\n",
    "\n",
    "Splink includes libraries of comparison functions to make it simple to get started:\n",
    "\n",
    "Let's start by looking at a `Comparison` for `first_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6143e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splink.duckdb.duckdb_comparison_library as cl\n",
    "\n",
    "first_name_comparison = cl.levenshtein_at_thresholds(\"first_name\", 2)\n",
    "print(first_name_comparison.human_readable_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7677a",
   "metadata": {},
   "source": [
    "## Specifying the full settings dictionary\n",
    "\n",
    "`Comparisons` are specified as part of the Splink `settings`, a Python dictionary which controls all of the configuration of a Splink model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"comparisons\": [\n",
    "        cl.levenshtein_at_thresholds(\"first_name\", 2),\n",
    "        cl.levenshtein_at_thresholds(\"surname\"),\n",
    "        cl.levenshtein_at_thresholds(\"dob\"),\n",
    "        cl.exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        cl.levenshtein_at_thresholds(\"email\"),\n",
    "    ],\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name\",\n",
    "        \"l.surname = r.surname\",\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a1fb8",
   "metadata": {},
   "source": [
    "In words, this setting dictionary says:\n",
    "\n",
    "\n",
    "* We are performing a `dedupe_only` (the other options are `link_only`, or `link_and_dedupe`, which may be used if there are multiple input datasets)\n",
    "* When comparing records, we will use information from the `first_name`, `surname`, `dob`, `city` and `email` columns to compute a match score.\n",
    "* The `blocking_rules_to_generate_predictions` states that we will only check for duplicates amongst records where either the `first_name` or `surname` is identical.\n",
    "* We have enabled term frequency adjustments for the 'city' column, because some values (e.g. `London`) appear much more frequently than others\n",
    "* We have set `retain_intermediate_calculation_columns` and `additional_columns_to_retain` to `True`  so that Splink outputs additional information that helps the user understand the calculations. If they were `False`, the computations would run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa31386",
   "metadata": {},
   "source": [
    "## Estimate the parameters of the model\n",
    "\n",
    "Now that we have specified our linkage model, we want to estimate its `m` and `u` parameters, and the [`probability_two_random_records_match`](https://moj-analytical-services.github.io/splink/settings_dict_guide.html#probability_two_random_records_match) parameter.\n",
    "\n",
    "- The `m` values are the proportion of records falling into each `ComparisonLevel` amongst truly *matching* records\n",
    "\n",
    "- The `u` values are the proportion of records falling into each `ComparisonLevel` amongst truly *non-matching* records\n",
    "\n",
    "- The `probability_two_random_records_match` parameter is the probability that two records taken at random from your input data represent a match (typically a very small number).\n",
    "\n",
    "You can read more about the theory of what these mean [here](https://www.robinlinacre.com/maths_of_fellegi_sunter/).\n",
    "\n",
    "\n",
    "In general, we can estimate the `u` parameters and the `probability_two_random_records_match` using direct estimation techniques, even if we do not have labelled data.\n",
    "\n",
    "If we do not have labelled data, the `m` parameters can be estimated using an iterative maximum likelihood approach called Exepctation Maximisation.  If we have labels, we can directly estimate the \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2871ac6",
   "metadata": {},
   "source": [
    "### Direct estimation of `probability_two_random_records_match`\n",
    "\n",
    "In some cases, the `probability_two_random_records_match` will be known. For example, if you are linking two tables of 10,000 records and expect a one-to-one match, then you should set this value to `1/10_000` in your settings instead of estimating it.\n",
    "\n",
    "More generally, this parameter is unknown and needs to be estimated.  \n",
    "\n",
    "It can be estimated accurately enough for most purposes by combining a series of deterministic matching rules and an guess of the recall corresopnding to those rules.  For further details of the rationale behind this appraoch see [here](https://github.com/moj-analytical-services/splink/issues/462#issuecomment-1227027995).\n",
    "\n",
    "In this example, I guess that the following deterministic matching rules have a recall of about 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf92120",
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\",\n",
    "    \"l.email = r.email\"\n",
    "]\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712860b",
   "metadata": {},
   "source": [
    "### Direct estimation of `u` probabilities\n",
    "\n",
    "Next, we will use `estimate_u_using_random_sampling` method to compute the `u` values of the model.   \n",
    "\n",
    "The larger the random sample, the more accurate the predictions.  You control this using the `max_pairs` parameter. For large datasets, we recommend using at least 10 million - but the higher the better and 1 billion is often appropriate for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d49e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73921b7",
   "metadata": {},
   "source": [
    "We then use the expectation maximisation algorithm to train the `m` values.\n",
    "\n",
    "This algorithm estimates the `m` values by generating pairwise record comparisons, and using them to maximise a likelihood function. \n",
    "\n",
    "Each estimation pass requires the user to configure an estimation blocking rule to reduce the number of record comparisons generated to a managable level.\n",
    "\n",
    "\n",
    "In our first estimation pass, we block on `first_name` and `surname`, meaning we will generate all record comparisons that have `first_name` and `surname` exactly equal.   \n",
    "\n",
    "Recall we are trying to estimate the `m` values of the model, i.e. proportion of records falling into each `ComparisonLevel` amongst truly matching records.\n",
    "\n",
    "This means that, in this training session, we cannot estimate parameter estimates for the `first_name` or `surname` columns, since we have forced them to be equal 100% of the time.\n",
    "\n",
    "We can, however, estimate parameter estimates for all of the other columns.  The output messages produced by Splink confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_fname_sname = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd4a31",
   "metadata": {},
   "source": [
    "In a second estimation pass, we block on dob. This allows us to estimate parameters for the `first_name` and `surname` comparisons.\n",
    "\n",
    "Between the two estimation passes, we now have parameter estimates for all comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import fix\n",
    "\n",
    "\n",
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb0c5f",
   "metadata": {},
   "source": [
    "Note that Splink includes other algorithms for estimating m and u values, which are documented [here](https://moj-analytical-services.github.io/splink/linkerest.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38355535",
   "metadata": {},
   "source": [
    "## Visualising model parameters\n",
    "\n",
    "Splink can generate a number of charts to help you understand your model.  For an introduction to these charts and how to interpret them, please see [this](https://www.youtube.com/watch?v=msz3T741KQI&t=507s) video.\n",
    "\n",
    "The final estimated match weights can be viewed in the match weights chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.m_u_parameters_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44fcc26",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "Finally we can save the model, including our estimated parameters, to a `.json` file, so we can use it in the next tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992703a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.save_settings_to_json(\"./demo_settings/saved_model_from_demo.json\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd531cd2",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now we have trained a model, we can move on to using it predict matching records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd8e7f",
   "metadata": {},
   "source": [
    "\n",
    "## Further reading\n",
    "\n",
    "Full documentation for all of the ways of estimating model parameters can be found [here](https://moj-analytical-services.github.io/splink/linkerest.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b53fa520a31e303a9636a08ff10a3bbc14893ee50cb37445791fa59628fc75b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
